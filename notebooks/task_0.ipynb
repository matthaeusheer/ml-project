{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scikitplot as skplot\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from pipelinehelper import PipelineHelper\n",
    "\n",
    "from context import ml_project\n",
    "from ml_project.io import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To surpress sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data - HowTo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the zip folder from the web  \n",
    "2) Create a directory inside the PROJECT_ROOT_DIR/data/ and give it a suitable name (DIR_NAME)  \n",
    "3) Extract the files from the zip folder into DIR_NAME  \n",
    "4) Set the correct DIR_NAME in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = 'task0_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data (train and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler(DIR_NAME)\n",
    "data = data_handler.load_train_and_test_data()\n",
    "\n",
    "train_X = data['train_data'].drop(['y'], axis=1)\n",
    "train_Y = data['train_data']['y']\n",
    "\n",
    "test_X = data['test_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model on training data and performing predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would be the actual procedure, given we would NOT know that the predicted value is the mean of all features\n",
    "\n",
    "pipe_clf = Pipeline([('std_scale', StandardScaler()),\n",
    "                     ('regr', PipelineHelper([\n",
    "                         ('linregr', LinearRegression()),\n",
    "                         ('sgdregr', SGDRegressor())\n",
    "                     ])),\n",
    "                     \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'regr__selected_model': pipe_clf.named_steps['regr'].generate({\n",
    "        'linregr__normalize': [True, False],\n",
    "        'sgdregr__alpha': [0.0001, 0.001, 0.01]\n",
    "    })\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(pipe_clf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=True)\n",
    "\n",
    "grid_clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions = pd.DataFrame(grid_clf.predict(test_X))\n",
    "\n",
    "predictions = predictions.rename(columns = {0:'y'})\n",
    "predictions.index = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid_clf.best_estimator_\n",
    "print('\\nBest estimator:\\n')\n",
    "pprint(best_estimator)\n",
    "\n",
    "print('\\nGridsearch CV results:\\n')\n",
    "pprint(grid_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplot.estimators.plot_learning_curve(grid_clf, train_X, train_Y, train_sizes=np.linspace(.1, 1.0, 10), \n",
    "                                      figsize=(13, 8), cv=3, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But... In this dummy task we know that the predicted value has to be the mean of the features, so\n",
    "pred_easy = pd.DataFrame(test_X.mean(axis=1)) \n",
    "pred_easy = pred_easy.rename(columns = {0:'y'})\n",
    "pred_easy.index = test_X.index\n",
    "pprint(pred_easy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing predictions back to disk in correct data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.store_prediction_file(pred_easy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-intro",
   "language": "python",
   "name": "ml-intro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
