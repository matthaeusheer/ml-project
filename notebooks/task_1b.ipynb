{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import scikitplot as skplot\\\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from pipelinehelper import PipelineHelper\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from notebooks.context import ml_project\n",
    "from ml_project.task_1.transformations import aggregate_feature_matrix, get_phi_callables\n",
    "from ml_project.io import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To surpress sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = '/Users/sluck/eth/introML/data/task1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated feature matrix of shape: (1000, 21)\nAggregated feature matrix of shape: (800, 21)\nAggregated feature matrix of shape: (200, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor \n",
    "data_handler = DataHandler(DIR_NAME)\n",
    "all_data = data_handler.load_train_data()\n",
    "\n",
    "# 80 20 is standart?\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data.drop(['y'], axis=1), \n",
    "                                                    all_data['y'], test_size=0.2,\n",
    "                                                    random_state=131\n",
    "                                                    )\n",
    "\n",
    "# Apply feature transforms\n",
    "feature_mat_all = pd.concat([aggregate_feature_matrix(all_data, get_phi_callables()), all_data['y']], axis=1)\n",
    "feature_mat_train = aggregate_feature_matrix(X_train, get_phi_callables())\n",
    "feature_mat_test = aggregate_feature_matrix(X_test, get_phi_callables())\n",
    "\n",
    "#outlier detect?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def my_scorer(y_true, y_predicted):\n",
    "    error = mean_squared_error(y_true, y_predicted)**0.5\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21) (800,)\nDone train\n(800,) (800,)\n(800, 1) (800,)\n<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\nWe are left with (626, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression,VarianceThreshold\n",
    "from sklearn.linear_model import ElasticNet,RidgeCV,Perceptron,TheilSenRegressor,LarsCV\n",
    "from sklearn.linear_model import Lasso,LassoCV\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "#print(feature_mat_train[['phi_1','phi_6','phi_11','phi_16']])\n",
    "from sklearn.cluster import DBSCAN\n",
    "outlier_detection = DBSCAN(\n",
    "  eps = 3.6,#3.1 for entire\n",
    "  metric=\"euclidean\",\n",
    "  min_samples = 50,\n",
    "  n_jobs = -1)\n",
    "clusters = outlier_detection.fit_predict(feature_mat_train)\n",
    "\n",
    "#clusters = outlier_detection.fit_predict(\n",
    "    #feature_mat_train[['phi_1','phi_2','phi_3','phi_4','phi_5']])\n",
    "# remove outliers\n",
    "#print(feature_mat_train)\n",
    "print(feature_mat_train.shape,clusters.shape)\n",
    "new_train=feature_mat_train\n",
    "new_train['outlier']=clusters\n",
    "feature_mat_train_new=new_train[new_train.outlier==0]\n",
    "feature_mat_train_new=feature_mat_train_new.drop(['outlier'],axis=1)\n",
    "#print(feature_mat_train_new.head())\n",
    "\n",
    "print(\"Done train\")\n",
    "\n",
    "print(y_train.shape,clusters.shape)\n",
    "new_y=y_train.to_frame()\n",
    "print(new_y.shape,clusters.shape)\n",
    "print(type(new_train),type(feature_mat_train_new))\n",
    "new_y['outlier']=clusters\n",
    "y_train_new=new_y[new_y.outlier==0]\n",
    "y_train_new=y_train_new.drop(['outlier'],axis=1)\n",
    "\n",
    "print(f\"We are left with {y_train_new.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the linear model and get weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10 11 12 13 14 15 16 17 18 19 20]\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan]\nshape: (626, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "my_func = make_scorer(my_scorer,greater_is_better=False)\n",
    "model=SelectKBest(k=13)\n",
    "test_sel=model.fit(feature_mat_train_new,y_train_new)\n",
    "test=test_sel.get_support(indices=True)\n",
    "print(test)\n",
    "print(test_sel.scores_)\n",
    "# lets remove all labels below 16\n",
    "# feature_mat_train_sel=feature_mat_train_new[\n",
    "#     [f'phi_{i}' for i in range(16,21)]\n",
    "# ]\n",
    "\n",
    "for i in range(1,16):\n",
    "    feature_mat_train_sel[f'phi_{i}']=0\n",
    "feature_mat_train_sel['phi_21']=0\n",
    "\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "                #('std_scale', StandardScaler()),\n",
    "                #('preprocess',([]))\n",
    "                #('minMaxScale',preprocessing.MinMaxScaler()),\n",
    "                # ('scale', PipelineHelper([\n",
    "                #      ('std_scale', StandardScaler()),\n",
    "                #      ('minMaxScale',preprocessing.MinMaxScaler()),\n",
    "                #   ])),\n",
    "                #('feature_select', SelectKBest()),\n",
    "                #('VR',VarianceThreshold()),\n",
    "                 #('baye_ridge', BayesianRidge()),\n",
    "                #('orthoMP',OrthogonalMatchingPursuitCV()),\n",
    "                 #('Lasso',Lasso()),\n",
    "                #('elas',ElasticNet()),\n",
    "                  ('regr', PipelineHelper([\n",
    "                      #('linregr', LinearRegression()),\n",
    "                      ('ridge', Ridge()),\n",
    "                      #('BR', BayesianRidge(fit_intercept=False)),\n",
    "                      # ('RidgeCV',RidgeCV()),\n",
    "                      # ('LarsCV',LarsCV()),\n",
    "                       #('Lasso',Lasso()),\n",
    "                      #('LassoCV',LassoCV(fit_intercept=False)),\n",
    "                      # ('TheilSenRegressor',TheilSenRegressor()),\n",
    "                      \n",
    "                      #('ARDRegression',ARDRegression())\n",
    "                  #     ('elas',ElasticNet()),\n",
    "                     #('orthoMP',OrthogonalMatchingPursuitCV()),\n",
    "                      #ortho doesnt work at all coefficients not good apperantly\n",
    "                  ])),                   \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    #'feature_select__k': [3],\n",
    "    #'VR__threshold':[1/(i*i*i) for i in range(1,10)],\n",
    "    #'orthoMP__cv':[8,9,10,11],\n",
    "    #'orthoMP__max_iter':[2,3,4,5],\n",
    "    #'elas__max_iter':[100,1000],    \n",
    "\n",
    "\n",
    "    'regr__selected_model': pipe.named_steps['regr'].generate({\n",
    "        #'ridge__alpha': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "        #'orthoMP__max_iter':[2,3,4,5,7,9],\n",
    "        # 'LassoCV__cv':[3,5,10],\n",
    "        # 'LassoCV__n_alphas':[20],\n",
    "        # 'LassoCV__positive':[False],\n",
    "        # 'LassoCV__selection':['cyclic'],\n",
    "        # 'LassoCV__tol':[1.0e-20],\n",
    "        'ridge__alpha': [500],\n",
    "        'ridge__fit_intercept':[False],\n",
    "        #'BR__tol':[1.0e-20],\n",
    "        #'BR__compute_score':[True],\n",
    "        #'Lasso__alpha':[512],\n",
    "        \n",
    "    })\n",
    "}\n",
    "print(\"shape:\",feature_mat_train_new.shape)\n",
    "grid_cv = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                       cv=10, scoring=my_func, \n",
    "                       verbose=False, refit=True)\n",
    "\n",
    "grid_cv = grid_cv.fit(feature_mat_train_new, y_train_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param set: \n{'regr__selected_model': ('ridge', {'alpha': 500, 'fit_intercept': False})}\n\n ----------\nMean test scores for parameter combinations...\n3.165 (+/- 1.540) for {'regr__selected_model': ('ridge', {'alpha': 500, 'fit_intercept': False})}\n----------\n"
     ]
    }
   ],
   "source": [
    "from ml_project.train.gridcv import print_gridcv_report\n",
    "print_gridcv_report(grid_cv, neg_sqr_of_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 21)\n(200, 1) (200,)\nRMSE on out of sample test set: 9.42841913367115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(feature_mat_test.shape)\n",
    "y_pred = grid_cv.predict(feature_mat_test)\n",
    "print(y_pred.shape,y_test.shape)\n",
    "\n",
    "print('RMSE on out of sample test set:', mean_squared_error(y_test, y_pred)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E> 'VR'\n"
     ]
    }
   ],
   "source": [
    "best_estimator = grid_cv.best_estimator_\n",
    "regr_model = best_estimator.named_steps['regr'].selected_model\n",
    "try:\n",
    "    print(best_estimator.named_steps['VR'].get_support(indices=True))\n",
    "except Exception as e:\n",
    "    print(f\"E> {e}\")\n",
    "    pass\n",
    "\n",
    "coefficients = regr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (weights) for feature transforms...\n\n\tphi_1: [ 0.83824709 -0.36363283 -0.19899983  0.19176308 -0.11030599 -0.8828808\n  0.17577547 -0.62196221 -0.1289628   0.4156626   0.47954058 -0.59116605\n -0.92879815 -0.04192099 -0.15666939  0.13928855 -0.27241754 -0.0027968\n -0.15434063 -0.34294541 -0.2162026 ]\n"
     ]
    }
   ],
   "source": [
    "def print_final_weights(coefficients):\n",
    "    print('Coefficients (weights) for feature transforms...\\n')\n",
    "    for feat_name, coeff in zip(get_phi_callables().keys(), coefficients):\n",
    "        print('\\t{}: {}'.format(feat_name, coeff))\n",
    "        \n",
    "print_final_weights(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At all [[ 0.83824709 -0.36363283 -0.19899983  0.19176308 -0.11030599 -0.8828808\n   0.17577547 -0.62196221 -0.1289628   0.4156626   0.47954058 -0.59116605\n  -0.92879815 -0.04192099 -0.15666939  0.13928855 -0.27241754 -0.0027968\n  -0.15434063 -0.34294541 -0.2162026 ]]\nAt o [ 0.83824709 -0.36363283 -0.19899983  0.19176308 -0.11030599 -0.8828808\n  0.17577547 -0.62196221 -0.1289628   0.4156626   0.47954058 -0.59116605\n -0.92879815 -0.04192099 -0.15666939  0.13928855 -0.27241754 -0.0027968\n -0.15434063 -0.34294541 -0.2162026 ]\nDiffrent format We need 21 in output but was 1\n[ 0.83824709 -0.36363283 -0.19899983  0.19176308 -0.11030599 -0.8828808\n  0.17577547 -0.62196221 -0.1289628   0.4156626   0.47954058 -0.59116605\n -0.92879815 -0.04192099 -0.15666939  0.13928855 -0.27241754 -0.0027968\n -0.15434063 -0.34294541 -0.2162026 ]\n"
     ]
    }
   ],
   "source": [
    "print('At all',coefficients)\n",
    "print('At o',coefficients[0])\n",
    "try:\n",
    "    assert len(coefficients)==21,f'We need 21 in output but was {len(coefficients)}'\n",
    "    data_handler.store_results_task1b(list(coefficients))\n",
    "    print(\"Done\")\n",
    "except Exception as e:\n",
    "    print(f\"Diffrent format {e}\")\n",
    "    assert len(coefficients[0])==21,f'We need 21 in output but was {len(coefficients[0])}'\n",
    "    data_handler.store_results_task1b(coefficients[0])\n",
    "    print(coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-intro",
   "language": "python",
   "name": "ml-intro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
