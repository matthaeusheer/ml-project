{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import scikitplot as skplot\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from context import ml_project\n",
    "from ml_project.io import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To surpress sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data - HowTo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the zip folder holding the data  \n",
    "2) Create a directory inside the <PROJECT_ROOT_DIR>/data and give it a suitable name <DIR_NAME>, e.g. \"task1a_data\"   \n",
    "3) Extract the files from the zip folder into <DIR_NAME>  \n",
    "4) Set the correct <DIR_NAME> in the following cell...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = 'task1a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler(DIR_NAME)\n",
    "train_data = data_handler.load_train_data()\n",
    "\n",
    "train_X = train_data.drop(['y'], axis=1)\n",
    "train_Y = train_data['y']\n",
    "\n",
    "train_data_full = pd.concat([train_Y, train_X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the correlatio of y and the feature values\n",
    "\n",
    "def plot_columns_serieses(df, columns=None, y_label='', x_label='Sample index'):\n",
    "    train_plot_X = df.copy()\n",
    "    \n",
    "    if columns:\n",
    "        train_plot_X = train_plot_X[columns]\n",
    "    \n",
    "    if hasattr(train_plot_X, 'columns'):\n",
    "        offset_val = 30\n",
    "        for idx, col in enumerate(train_plot_X.columns):\n",
    "            train_plot_X[col] = train_plot_X[col] + offset_val * idx\n",
    "\n",
    "    ax = train_plot_X.plot(figsize=(18, 5), legend=False, alpha=0.7)\n",
    "    sns.despine(left=True, bottom=True, right=True)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], facecolor='None', frameon=False, ncol=10)\n",
    "    plt.show()\n",
    "    \n",
    "plot_columns_serieses(train_X, y_label='Feature values vs indexes')\n",
    "plot_columns_serieses(train_data_full, columns='y', y_label='Target variable y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_correlation_plot(data_frame):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    correlation = data_frame.corr() #corr() method of pandas library calculates correlation between columns of dataframe\n",
    "    sns.heatmap(correlation, cmap=\"YlGnBu\", annot=True)\n",
    "    plt.show()\n",
    "\n",
    "sns_correlation_plot(train_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "_ = scatter_matrix(pd.concat([train_Y, train_X], axis=1), alpha=0.3, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_cleaned=train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each of the pre-defined regularization values, we create a Pipeline consisting of a the ridge regressor itself.\n",
    "If we wanted, we could easily add more steps into the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "ridge_alphas = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "models = {}\n",
    "for alpha_value in ridge_alphas:\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "                         ('regr', Ridge(alpha=alpha_value, fit_intercept=False))])\n",
    "    \n",
    "    models[alpha_value] = pipeline\n",
    "\n",
    "param_grid = {\n",
    "              'regr__random_state': [404], \n",
    "             }\n",
    "\n",
    "grid_cv_estimators = {}\n",
    "for alpha_value, ridge_pipe in models.items():\n",
    "    \n",
    "    print('Training models with alpha value {}'.format(ridge_pipe.get_params()['regr__alpha']))\n",
    "    \n",
    "    grid_cv = GridSearchCV(ridge_pipe, param_grid=param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error', verbose=True)\n",
    "    grid_cv.fit(train_X_cleaned, train_Y)\n",
    "    grid_cv_estimators[alpha_value] = grid_cv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for alpha_val, cv_estimator in grid_cv_estimators.items():\n",
    "    print('\\n', 10 * '=', 'alpha = {}'.format(alpha_val), 10 * '=', '\\n')\n",
    "    print('Best param set: ')\n",
    "    pprint(cv_estimator.best_params_)\n",
    "\n",
    "    cv_results = cv_estimator.cv_results_\n",
    "    \n",
    "    best_ranked_idx = np.argmin(cv_results['rank_test_score'])\n",
    "    results.append(cv_results['mean_test_score'][best_ranked_idx])\n",
    "    \n",
    "    print('\\n', 10 * '-')\n",
    "    print('Mean test scores for parameter combinations...')\n",
    "    for mean, std, params in zip(cv_results['mean_test_score'], cv_results['std_test_score'], cv_results['params']):\n",
    "        print(\"%0.3f (+/- %0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print(10 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "pos_results = [np.sqrt(-1.0 * entry) for entry in results]\n",
    "# Since sklearn optimizes for high values of neg_mean_square_error\n",
    "\n",
    "print('Mean squared error for alpha values of...\\n')\n",
    "for alpha, av_msqe in zip(ridge_alphas, pos_results):\n",
    "    print('{:15}: {}'.format(alpha, av_msqe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.store_results_task1a(pos_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
