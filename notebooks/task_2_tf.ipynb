{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from context import ml_project\n",
    "from ml_project.io import DataHandler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# To surpress sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the zip folder holding the data  \n",
    "2) Create a directory inside the PROJECT_ROOT_DIR/data and give it a suitable name DIR_NAME, e.g. \"task1b_data\"   \n",
    "3) Extract the files from the zip folder into <DIR_NAME>  \n",
    "4) Set the correct DIR_NAME in the following cell...  (no need for full absolute path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = 'task2_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and aggregate feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler(DIR_NAME)\n",
    "train_data = data_handler.load_train_data()\n",
    "final_test_data = data_handler.load_test_data()  # only used for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HELD_OUT_TEST_SET_SIZE = 0.2  # used for out of sample classifier performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['y'], axis=1), \n",
    "                                                    train_data['y'], \n",
    "                                                    test_size=HELD_OUT_TEST_SET_SIZE,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.as_matrix(), X_test.as_matrix(), y_train.as_matrix(), y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "SHOW_PLOT = False  # switch to True if you want to see the scatter plot\n",
    "if SHOW_PLOT:\n",
    "    _ = scatter_matrix(pd.concat([y_train, X_train], axis=1), alpha=0.3, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    \n",
    "    keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.3, noise_shape=None, seed=None),\n",
    "    \n",
    "    keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.3, noise_shape=None, seed=None),\n",
    "\n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=60, validation_split=0.2, verbose=0, shuffle=True, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(models, key='acc'):\n",
    "    plt.figure(figsize=(16,10))\n",
    "\n",
    "    for name, model in models:\n",
    "        history = model.history\n",
    "        try:\n",
    "            val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                           '--', label=name.title()+' Val')\n",
    "        except:\n",
    "            pass\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "                 label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "\n",
    "plot_history([('baseline', model)])  # can add more models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation on held out test dat\n",
    "This is the section where we get a sense of how well our trained model is doing on the part of the training set we did not touch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from scikitplot.metrics import plot_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = [np.argmax(proba) for proba in y_pred_proba]\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(y_test, y_pred, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc(y_test, y_pred_proba, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform prediction on provided test data set\n",
    "Now we perform predictions on the provided, unlabelled data set for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = [np.argmax(proba) for proba in model.predict(final_test_data)]\n",
    "y_pred_ids = final_test_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the data\n",
    "Putting everything into the right format and storing the results in the working data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.store_results_task2(y_pred_final, y_pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-intro",
   "language": "python",
   "name": "ml-intro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
