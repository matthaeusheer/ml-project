{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from context import ml_project\n",
    "from ml_project.io import DataHandler\n",
    "from ml_project.train import neural_nets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# To surpress sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the zip folder holding the data  \n",
    "2) Create a directory inside the PROJECT_ROOT_DIR/data and give it a suitable name DIR_NAME, e.g. \"task1b_data\"   \n",
    "3) Extract the files from the zip folder into <DIR_NAME>  \n",
    "4) Set the correct DIR_NAME in the following cell...  (no need for full absolute path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = 'task3_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and aggregate feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler(DIR_NAME)\n",
    "train_data = data_handler.load_train_data('train.h5', 'h5')\n",
    "final_test_data = data_handler.load_test_data('test.h5', 'h5')  # only used for submission\n",
    "final_indices = final_test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HELD_OUT_TEST_SET_SIZE = 0.2  # used for out of sample classifier performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['y'], axis=1), \n",
    "                                                    train_data['y'], \n",
    "                                                    test_size=HELD_OUT_TEST_SET_SIZE,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.as_matrix(), X_test.as_matrix(), y_train.as_matrix(), y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#_test = scaler.transform(X_test)\n",
    "#final_test_data = scaler.transform(final_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to build, compile and fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_model(units_first, units_second, units_third, n_final_classes):\n",
    "    \"\"\"Creates three layer model with dropout and regularization.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(units_first, activation=tf.nn.relu),\n",
    "\n",
    "        keras.layers.Dense(units_second, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.3, noise_shape=None, seed=None),\n",
    "\n",
    "        keras.layers.Dense(units_third, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.3, noise_shape=None, seed=None),\n",
    "\n",
    "        keras.layers.Dense(n_final_classes, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def fit_model(model, epochs, callbacks):\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, verbose=1, shuffle=True, workers=-1,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks and tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import DATA_DIR_PATH\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(DATA_DIR_PATH, DIR_NAME, 'logs')\n",
    "tensorboard = callbacks.TensorBoard()\n",
    "early_stopping = callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U can define multiple models and compare them\n",
    "\"\"\"\n",
    "models = [('small',  compile_model(three_layer_model(128, 128, 128, 5))),\n",
    "          ('medium', compile_model(three_layer_model(256, 256, 256, 5))),\n",
    "          ('large',  compile_model(three_layer_model(512, 512, 512, 5)))]\n",
    "\"\"\"\n",
    "# Or if u decided which one to use just define one and use it\n",
    "models = [('baseline', compile_model(three_layer_model(128, 128, 128, 5)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "\n",
    "for name, model in models:\n",
    "    print(f'Fitting model {name}...')\n",
    "    log_path = os.path.join(LOG_DIR, name + '_' + neural_nets.get_date_time_tag())\n",
    "    tensorboard.log_dir = log_path\n",
    "    fit_model(model, epochs=EPOCHS, callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets.plot_history(models)  # can add more models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models):\n",
    "    results = {}\n",
    "    for name, model in models:\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        results[name] = {'test accuracy': test_acc, 'test loss': test_loss}\n",
    "\n",
    "    return pd.DataFrame(results).transpose()\n",
    "\n",
    "results_df = evaluate_models(models)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(results_df, models):\n",
    "    best_model_name = results_df.idxmax()['test accuracy']\n",
    "    best_model = None\n",
    "    for name, model in models:\n",
    "        if name == best_model_name:\n",
    "            best_model = model\n",
    "            break\n",
    "    return best_model_name, best_model\n",
    "\n",
    "best_model_name, model = select_best_model(results_df, models)\n",
    "print(f'Best model: {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation on held out test dat\n",
    "This is the section where we get a sense of how well our trained model is doing on the part of the training set we did not touch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from scikitplot.metrics import plot_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = [np.argmax(proba) for proba in y_pred_proba]\n",
    "    _ = plot_confusion_matrix(y_test, y_pred, figsize=(12, 8))\n",
    "    _ = plot_roc(y_test, y_pred_proba, figsize=(8, 8))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform prediction on provided test data set\n",
    "Now we perform predictions on the provided, unlabelled data set for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = [np.argmax(proba) for proba in model.predict(final_test_data)]\n",
    "y_pred_ids = final_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the data\n",
    "Putting everything into the right format and storing the results in the working data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.store_results_task3(y_pred_final, y_pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-intro",
   "language": "python",
   "name": "ml-intro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
